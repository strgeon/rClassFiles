0
00:00:00,000 --> 00:00:00,500


1
00:00:00,500 --> 00:00:04,370
Let's begin by creating a data frame called emails

2
00:00:04,370 --> 00:00:07,690
using the read.csv function.

3
00:00:07,690 --> 00:00:09,650
And loading up energy_bids.csv.

4
00:00:09,650 --> 00:00:12,710


5
00:00:12,710 --> 00:00:15,310
And as always, in the text analytics week,

6
00:00:15,310 --> 00:00:20,560
we're going to pass stringsAsFactors=FALSE to this

7
00:00:20,560 --> 00:00:22,660
function.

8
00:00:22,660 --> 00:00:26,230
So we can take a look at the structure of our new data frame

9
00:00:26,230 --> 00:00:29,230
using the str function.

10
00:00:29,230 --> 00:00:32,060
We can see that there are 855 observations.

11
00:00:32,060 --> 00:00:35,730
This means we have 855 labeled emails in the data set.

12
00:00:35,730 --> 00:00:38,930
And for each one we have the text of the email

13
00:00:38,930 --> 00:00:41,410
and whether or not it's responsive to our query

14
00:00:41,410 --> 00:00:44,660
about energy schedules and bids.

15
00:00:44,660 --> 00:00:47,660
So let's take a look at a few example emails in the data set,

16
00:00:47,660 --> 00:00:49,300
starting with the first one.

17
00:00:49,300 --> 00:00:54,610
So the first email can be accessed with emails$email[1],

18
00:00:54,610 --> 00:00:57,060
and we'll select the first one.

19
00:00:57,060 --> 00:01:00,940
So while the output you get when you type this

20
00:01:00,940 --> 00:01:04,514
will depend on what operating system you're running on,

21
00:01:04,514 --> 00:01:06,430
many of you will see what I'm displaying here.

22
00:01:06,430 --> 00:01:08,090
Which is a single line of text that we

23
00:01:08,090 --> 00:01:11,210
need to horizontally scroll to read through.

24
00:01:11,210 --> 00:01:14,460
This is a pretty tough way to read a long piece of text.

25
00:01:14,460 --> 00:01:16,990
So if you have this sort of display,

26
00:01:16,990 --> 00:01:22,450
you can use the strwrap function and pass it the long string you

27
00:01:22,450 --> 00:01:26,360
want to print out, in this case emails$email.

28
00:01:26,360 --> 00:01:28,610
Selecting the first one.

29
00:01:28,610 --> 00:01:31,620
And now we can see that this has broken down our long string

30
00:01:31,620 --> 00:01:36,150
into multiple shorter lines that are much easier to read.

31
00:01:36,150 --> 00:01:37,240
OK.

32
00:01:37,240 --> 00:01:39,220
So let's take a look now at this email,

33
00:01:39,220 --> 00:01:41,786
now that it's a lot easier to read.

34
00:01:41,786 --> 00:01:43,910
We can see just by parsing through the first couple

35
00:01:43,910 --> 00:01:46,140
of lines that this is an email that's

36
00:01:46,140 --> 00:01:48,450
talking about a new working paper,

37
00:01:48,450 --> 00:01:51,430
"The Environmental Challenges and Opportunities

38
00:01:51,430 --> 00:01:53,990
in the Evolving North American Electricity Market"

39
00:01:53,990 --> 00:01:55,870
is the name of the paper.

40
00:01:55,870 --> 00:01:58,640
And it's being released by the Commission

41
00:01:58,640 --> 00:02:01,300
for Environmental Cooperation, or CEC.

42
00:02:01,300 --> 00:02:04,430
So while this certainly deals with electricity markets,

43
00:02:04,430 --> 00:02:07,610
it doesn't have to do with energy schedules or bids.

44
00:02:07,610 --> 00:02:10,710
So it is not responsive to our query.

45
00:02:10,710 --> 00:02:14,480
So we can take a look at the value in the responsive

46
00:02:14,480 --> 00:02:21,640
variable for this email using emails$responsive and selecting

47
00:02:21,640 --> 00:02:23,250
the first one.

48
00:02:23,250 --> 00:02:25,170
And we have value 0 there.

49
00:02:25,170 --> 00:02:28,130
So let's take a look at the second email in our data set.

50
00:02:28,130 --> 00:02:30,759
Again I'm going to use the strwrap function.

51
00:02:30,759 --> 00:02:32,800
I'm going to pass it emails$email[2].

52
00:02:32,800 --> 00:02:38,220


53
00:02:38,220 --> 00:02:40,422
And scrolling up to the top here we can

54
00:02:40,422 --> 00:02:42,630
see that the original message is actually very short,

55
00:02:42,630 --> 00:02:45,540
it just says FYI (For Your Information),

56
00:02:45,540 --> 00:02:48,120
and most of it is a forwarded message.

57
00:02:48,120 --> 00:02:49,910
So we have all the people who originally

58
00:02:49,910 --> 00:02:51,770
received the message.

59
00:02:51,770 --> 00:02:54,780
And then down at the very bottom is the message itself.

60
00:02:54,780 --> 00:02:58,340
"Attached is my report prepared on behalf of the California

61
00:02:58,340 --> 00:03:00,170
State auditor."

62
00:03:00,170 --> 00:03:03,920
And there's an attached report, ca report new.pdf.

63
00:03:03,920 --> 00:03:07,450
Now our data set contains just the text of the emails

64
00:03:07,450 --> 00:03:09,410
and not the text of the attachments.

65
00:03:09,410 --> 00:03:11,790
But it turns out, as we might expect,

66
00:03:11,790 --> 00:03:14,770
that this attachment had to do with Enron's electricity bids

67
00:03:14,770 --> 00:03:16,040
in California,

68
00:03:16,040 --> 00:03:18,920
and therefore it is responsive to our query.

69
00:03:18,920 --> 00:03:21,360
And we can check this in the responsive variable.

70
00:03:21,360 --> 00:03:22,235
emails$responsive[2].

71
00:03:22,235 --> 00:03:26,890


72
00:03:26,890 --> 00:03:29,240
And we see that that's a 1.

73
00:03:29,240 --> 00:03:31,040
So now let's look at the breakdown

74
00:03:31,040 --> 00:03:34,710
of the number of emails that are responsive to our query using

75
00:03:34,710 --> 00:03:36,682
the table function.

76
00:03:36,682 --> 00:03:38,390
We're going to pass it emails$responsive.

77
00:03:38,390 --> 00:03:41,115


78
00:03:41,115 --> 00:03:43,710
And as we can see the data set is unbalanced,

79
00:03:43,710 --> 00:03:46,690
with a relatively small proportion of emails responsive

80
00:03:46,690 --> 00:03:47,670
to the query.

81
00:03:47,670 --> 00:03:51,220
And this is typical in predictive coding problems.

82
00:03:51,220 --> 00:03:52,337


